{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of a simple SOSP model of classic agreement attraction\n",
    "\n",
    "## Introduction\n",
    "Starting with a featural lexical-dependency grammar, we design a Harmony Function (HF).  The function is defined on a space of link and treelet feature variables.  The gradient of HF gives the dynamics of processing, i.e., it specifies the way the link and feature values change from any initial state.  Sentence comprehension consists of (c1) starting with the system in an initial state in which all variables have the value 0, (c2) perceiving a word, which results in the setting of a subset of treelet features to non-zero values, (c3) gravitating under the dynamics + noise to a low velocity threshold (this generally results in nearly reaching a local harmony peak), and repeating from step (c2) until all the words in the sequence to be comprehended have been processed.  Random production (useful for probing the non-contextualized distribution over parse trajectories) is accomplished by (p1) starting in the zero state, (p2) using the prior of initial word likelihoods to select a word, (p3) activating the treelet features associated with that word, (p4) gravitating under the dynamics + noise to the low velocity threshold, (p5) generating a distribution over next words from the ensemble of open lexical attachment site activations, (p6) generating a new word, and repeating from step (p3) until (p4) has produced maximal harmony or a practical limit on sentence length has been exceeded.  (The case of production of language in a discourse context will be discussed separately.)\n",
    "\n",
    "In this case, we focus on the process of producing a number-inflected verb after already having produced a subject NP of the form *The N1 Prep the N2*. This models the classic sentence completion paradigm of Bock & Miller (1991) and many subsequent experiments. The general finding is that people produce a more incorrect plural verbs following *the N1[sg] Prep the N2[pl]* than *the N1[sg] Prep the N2[sg]*.\n",
    "\n",
    "## Grammar, representation, & dynamics\n",
    "In a fuller model, the grammar is a collection of lexically anchored treelets. Each treelet consists of a mother and a finite number of daughters, some of which may be marked \"optional\". The mother and daughters are vectors of features, all of the same dimension, with the same interpretation assigned to each dimension. The harmony of a parse (which corresponds to an attractor at a harmony peak) is determined by the feature match between the attachment sites on linked treelets. Perfect feature match results in a harmony value of 1.0, with lower harmony values for feature mismatches and failures to attach required dependents.\n",
    "\n",
    "To illustrate the dynamics of choosing a verb after having processed the subject NP, simplify the state space down to just three dimenions. The three dimensions represent the number markings on N1, N2, and the verb, with 0 coding singular (S) and 1 coding plural (P). Thus, each corner of the unit hypercube is a simple representation of a possible parse (including both grammatical and ungrammatical sequences of words). We define these points (which will be fixed points of the processing dynamics below). The following figure illustrates the state space:\n",
    "\n",
    "![title](Figures/AgrAttrStateSpace.pdf)\n",
    "\n",
    "The size of the dot at a vertex represents the relative magnitude of its harmony value, as discussed next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up an array of fixed points (centers of the summed Gaussians discussed below)\n",
    "import numpy as np\n",
    "\n",
    "centers = np.array([[0, 0, 0], # SSS\n",
    "                   [0, 0, 1],  # SSP\n",
    "                   [0, 1, 0],  # SPS\n",
    "                   [0, 1, 1],  # SPP\n",
    "                   [1, 0, 0],  # PSS\n",
    "                   [1, 0, 1],  # PSP\n",
    "                   [1, 1, 0],  # PPS\n",
    "                   [1, 1, 1]])  # PPP\n",
    "center_labels = ['SSS', 'SSP', 'SPS', 'SPP', 'PSS', 'PSP', 'PPS', 'PPP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The harmony values for each of these vertices was determined in the following way:\n",
    "- Correct parses (SSS, SPS, PSP, and PPP) have a harmony value of 1.0.\n",
    "- A parse that has no feature match but has an incorrect attachment (here, N2 attaching as the subject of the verb to control the verb's number: SPP, PSS) was penalized by multiplying its harmony by 0.2.\n",
    "- A parse in which any attachment results in a feature clash (SSP, PPS) was penalized with the harmony multiplier 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The order of the harmony values corresponds to the order of the centers in the last code block.\n",
    "# produced LARGE amounts of attraction in the PS and PP conditions:\n",
    "#harmony_values = np.array([1, 0.01, 1, 0.2, 0.2, 2, 0.01, 2])\n",
    "# produced reasonable rates of attraction, but no sg./pl. asymmetry\n",
    "harmony_values = np.array([1, 0.01, 1, 0.2, 0.2, 1, 0.01, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to build the global harmony function, HF, out of the local harmony values. The global harmony function, $HF(\\mathbf{s})$, is constructed by placing a Gaussian RBF, $\\phi_i(\\mathbf{s})$ at each local harmony locus $i$, scaled by the local harmony of that  $h_i$ (Muezzinoglu & Zurada, 2006):\n",
    "\n",
    "$$HF(\\mathbf{s}) = \\sum_{i \\in Centers} h_i\\ \\phi_i(\\mathbf{s})$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\phi_i(\\mathbf{s}) = \\exp{\\left(-\\frac{\\Vert\\mathbf{s} - \\mathbf{c}_i\\Vert^2_2}{\\gamma}\\right)}$$\n",
    "\n",
    "Here, $\\mathbf{s}$ is the system state, i.e., the vector of activations of all the links and features. Each of these values ranges, in principle, over $(-\\infty, \\infty)$, but because of the design of the harmony function, the values will stay close the interval $[0, 1]$. $\\mathbf{c}_i$ is the center of the $i$th Gaussian, each of which defines an attractor of the system dynamics below. $\\gamma$ is a free parameter which specifies the widths of the RBFs, and thus determines how strongly the system prefers to achieve optimal parses (greater $\\gamma$ means stronger preference for maximal harmony). $\\Vert\\cdot\\Vert^2_2$ is the squared Euclidean distance (or the squared L2-norm).\n",
    "\n",
    "The dynamics of the system are given by the gradient of the harmony + noise:\n",
    "\n",
    "$$\\dot{\\mathbf{s}} = \\nabla HF + \\alpha\\cdot\\eta = -\\frac{2}{\\gamma}\\sum_{i} h_i\\ (\\mathbf{s} - \\mathbf{c}_i) \\cdot \\phi_i(\\mathbf{s})\\ + \\ \\alpha\\cdot\\eta$$\n",
    "\n",
    "where $\\dot{\\mathbf{s}}$ denotes the change in the state variable with respect to time and $\\eta$ is normally distributed noise. The magnitude, $\\alpha$, of the noise is a free parameter.\n",
    "\n",
    "By making the the system dynamics equal to the gradient of the harmony function, the system \"tries\" to take the steepest path possible to increase harmony (modulo the effect of the noise).\n",
    "\n",
    "In the simplified system we are currently considering, $\\mathbf{s}$ is a vector in $\\mathbb{R}^3$, there are six centers (given in `centers` above), and the harmony values of each center are given in `harmony_values`.\n",
    "\n",
    "## Running the agreement attraction simulation\n",
    "We can now run the simulation to test whether the simplified system. Here, we run the system starting from an initial state $\\mathbf{s}_0$ until $\\mathbf{s}$ is sufficiently close to an attractor or a maximum amount of time has passed. $\\mathbf{s}_0$ encodes what linguistic information has come before; thus, $[0, 1, 0.5]$, e.g., is the starting point for choosing a verb after producing a singular N1 and a plural N2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Condition: N1sg N2pl\n",
      "Of 500: [100] [200] [300] [400] [500] \n",
      "Condition: N1sg N2sg\n",
      "Of 500: [100] [200] [300] [400] [500] \n",
      "Condition: N1pl N2sg\n",
      "Of 500: [100] [200] [300] [400] [500] \n",
      "Condition: N1pl N2pl\n",
      "Of 500: [100] [200] [300] [400] [500] "
     ]
    }
   ],
   "source": [
    "# Setting the random seed for replicability\n",
    "np.random.seed(1)\n",
    "\n",
    "# Parameters\n",
    "tau = 0.1  # step size for the discretized (Euler forward) dynamics; this seems large...\n",
    "maxsteps = 1000  # maximum number of timesteps before terminating integration\n",
    "nruns = 500  # number of runs to do per condition\n",
    "tol = 0.1  # how close the system has to be to a corner to stop processing\n",
    "alpha = 0.1  # noise magnitude\n",
    "gamma = 0.1  # width of RBFs\n",
    "ndim = centers.shape[1]  # number of dimensions in the state space\n",
    "\n",
    "# Conditions, specified as s0 coordinates\n",
    "conditions = np.array([[0, 1, 0.5],  # SP\n",
    "                      [0, 0, 0.5],  # SS\n",
    "                      [1, 0, 0.5],  # PS\n",
    "                      [1, 1, 0.5]])  # PP\n",
    "condition_labels = ['N1sg N2pl', 'N1sg N2sg', 'N1pl N2sg', 'N1pl N2pl']\n",
    "ncond = len(condition_labels)\n",
    "\n",
    "# Defining phi function\n",
    "def phi(x, center, gamma):\n",
    "    diff = x - center\n",
    "    l2norm = np.sqrt(np.dot(diff, diff))\n",
    "    phi = np.exp(-l2norm**2 / gamma)\n",
    "    return phi\n",
    "\n",
    "\n",
    "# A function for updating the state of the system according to the negative\n",
    "# gradient of the harmony function\n",
    "def step_dyn(x, centers, harmonies, gamma):\n",
    "    dx = np.zeros(x.shape)\n",
    "    for c in range(centers.shape[0]):\n",
    "        dx += (-2./gamma * harmonies[c]\n",
    "               * (x - centers[c,:]) * phi(x, centers[c,:], gamma))\n",
    "    return dx\n",
    "\n",
    "\n",
    "# Proximity to a fixed point\n",
    "def not_close(x, centers, tol):\n",
    "    for c in range(centers.shape[0]):\n",
    "        diff = x - centers[c]\n",
    "        l2norm = np.sqrt(np.dot(diff, diff))\n",
    "        if l2norm < tol:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "\n",
    "# Singular or plural verb?\n",
    "def sg_pl(x):\n",
    "    x = np.round(x)\n",
    "    if x[-1] == 0:\n",
    "        return 0\n",
    "    elif x[-1] == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "# Find out which fp. the system reached; not currently used!\n",
    "def which_attr(x):\n",
    "    x = np.round(x)\n",
    "    for c in range(centers.shape[0]):\n",
    "        if np.all(x == centers[c,]):\n",
    "            return c\n",
    "    return -1\n",
    "\n",
    "# Doing the simulations\n",
    "parses = np.zeros((nruns, ncond))\n",
    "for cond in range(ncond):\n",
    "    print('\\nCondition: {}'.format(condition_labels[cond]))\n",
    "    print('Of {}: '.format(nruns), end='')\n",
    "    for run in range(nruns):\n",
    "        if (run+1) % 100 == 0:\n",
    "            print('[{}] '.format(run+1), end='')\n",
    "        x = np.zeros((maxsteps, ndim))\n",
    "        x[0,] = conditions[cond,]\n",
    "        noise = np.random.normal(0, alpha, x.shape)\n",
    "\n",
    "        t = 0\n",
    "        while t < maxsteps-1:\n",
    "            if not_close(x[t,], centers, tol = tol):\n",
    "                x[t+1,] = x[t,]+(tau*(step_dyn(x[t,], centers, harmony_values, gamma))\n",
    "                                 + noise[t,])\n",
    "                t += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        xtrunc = x[~np.all(x == 0, axis=1)]  # \n",
    "        #parses[run, cond] = which_attr(xtrunc[-1,])\n",
    "        parses[run, cond] = sg_pl(xtrunc[-1,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N1sg N2pl:\n",
      "\tVsg:\t0.934\n",
      "\tVpl:\t0.04\n",
      "\tother:\t0.026\n",
      "\n",
      "N1sg N2sg:\n",
      "\tVsg:\t0.982\n",
      "\tVpl:\t0.012\n",
      "\tother:\t0.006\n",
      "\n",
      "N1pl N2sg:\n",
      "\tVsg:\t0.046\n",
      "\tVpl:\t0.934\n",
      "\tother:\t0.02\n",
      "\n",
      "N1pl N2pl:\n",
      "\tVsg:\t0.046\n",
      "\tVpl:\t0.94\n",
      "\tother:\t0.014\n"
     ]
    }
   ],
   "source": [
    "# Now, just looking at the final distribution of parses:\n",
    "parse_labels = ['Vsg', 'Vpl', 'other']\n",
    "for cond in range(ncond):\n",
    "    uniq, cts = np.unique(parses[:,cond], return_counts=True)\n",
    "    print('\\n{}:'.format(condition_labels[cond]))\n",
    "    for u in range(len(uniq)):\n",
    "        if cts[u] is not 0:\n",
    "            #print('\\t{}:\\t{}'.format(center_labels[u], cts[u]))\n",
    "            print('\\t{}:\\t{}'.format(parse_labels[u], cts[u]/nruns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
